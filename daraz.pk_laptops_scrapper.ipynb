{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f934b1b",
   "metadata": {},
   "source": [
    "## Importing required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26c13b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from pandas import pandas as pd\n",
    "from selenium.webdriver.chrome.options import Options"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd1c6bc",
   "metadata": {},
   "source": [
    "## Initializing webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d69d472f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--headless')\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='C:\\webdriver\\chromedriver.exe', options=chrome_options)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84adb8bf",
   "metadata": {},
   "source": [
    "## Main scrapping Logic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61468266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapping page: 1\n",
      "Scrapping page: 2\n",
      "Scrapping page: 3\n",
      "Scrapping page: 4\n",
      "Scrapping page: 5\n",
      "Scrapping page: 6\n",
      "Scrapping page: 7\n",
      "Scrapping page: 8\n",
      "Scrapping page: 9\n",
      "Scrapping page: 10\n",
      "Scrapping page: 11\n",
      "Scrapping page: 12\n",
      "Scrapping page: 13\n",
      "Scrapping page: 13\n",
      "Scrapping page: 14\n",
      "Scrapping page: 15\n",
      "Scrapping page: 16\n",
      "Scrapping page: 17\n",
      "Scrapping page: 18\n",
      "Scrapping page: 19\n",
      "Scrapping page: 20\n",
      "Scrapping page: 20\n",
      "Scrapping page: 21\n",
      "Scrapping page: 22\n",
      "Scrapping page: 22\n",
      "Scrapping page: 23\n",
      "Scrapping page: 24\n",
      "Scrapping page: 25\n",
      "Scrapping page: 26\n",
      "Scrapping page: 27\n",
      "Scrapping page: 28\n",
      "Scrapping page: 29\n",
      "Scrapping page: 30\n",
      "Scrapping page: 31\n",
      "Scrapping page: 32\n",
      "Scrapping page: 32\n",
      "Scrapping page: 33\n",
      "Scrapping page: 34\n",
      "Scrapping page: 35\n",
      "Scrapping page: 35\n",
      "Scrapping page: 36\n",
      "Scrapping page: 37\n",
      "Scrapping page: 37\n",
      "Scrapping page: 38\n",
      "Scrapping page: 39\n",
      "Scrapping page: 40\n",
      "Scrapping page: 41\n",
      "Scrapping page: 42\n",
      "Scrapping page: 43\n",
      "Scrapping page: 44\n",
      "Scrapping page: 45\n",
      "Scrapping page: 46\n",
      "Scrapping page: 47\n",
      "Scrapping page: 48\n",
      "Scrapping page: 49\n",
      "Scrapping page: 50\n",
      "Scrapping page: 51\n",
      "Scrapping page: 52\n",
      "Scrapping page: 53\n",
      "Scrapping page: 53\n",
      "Scrapping page: 54\n",
      "Scrapping page: 54\n",
      "Scrapping page: 55\n",
      "Scrapping page: 56\n",
      "Scrapping page: 56\n",
      "Scrapping page: 57\n",
      "Scrapping page: 58\n",
      "Scrapping page: 59\n",
      "Scrapping page: 60\n",
      "Scrapping page: 61\n",
      "Scrapping page: 62\n",
      "Scrapping page: 63\n",
      "Scrapping page: 64\n",
      "Scrapping page: 65\n",
      "Scrapping page: 66\n",
      "Scrapping page: 67\n",
      "Scrapping page: 67\n",
      "Scrapping page: 67\n",
      "Scrapping page: 68\n",
      "Scrapping page: 69\n",
      "Scrapping page: 70\n",
      "Scrapping page: 71\n",
      "Scrapping page: 72\n",
      "Scrapping page: 73\n",
      "Scrapping page: 74\n",
      "Scrapping page: 75\n",
      "Scrapping page: 76\n",
      "Scrapping page: 77\n",
      "Scrapping page: 78\n",
      "Scrapping page: 79\n",
      "Scrapping page: 80\n",
      "Scrapping page: 81\n",
      "Scrapping page: 82\n",
      "Scrapping page: 83\n",
      "Scrapping page: 84\n",
      "Scrapping page: 85\n",
      "Scrapping page: 86\n",
      "Scrapping page: 87\n",
      "Scrapping page: 87\n",
      "Scrapping page: 88\n",
      "Scrapping page: 89\n",
      "Scrapping page: 90\n",
      "Scrapping page: 91\n",
      "Scrapping page: 92\n",
      "Scrapping page: 92\n",
      "Scrapping page: 93\n",
      "Scrapping page: 94\n",
      "Scrapping page: 95\n",
      "Scrapping page: 96\n",
      "Scrapping page: 97\n",
      "Scrapping page: 98\n",
      "Scrapping page: 99\n",
      "Scrapping page: 100\n",
      "Scrapping page: 101\n",
      "Scrapping page: 102\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'Title': [],'Daraz_Mall': [], 'Price': [], 'Total_Ratings': [], 'Country': []}\n",
    "\n",
    "total_pages = 2\n",
    "page = 1\n",
    "\n",
    "while page <= int(total_pages):\n",
    "    time.sleep(2)\n",
    "    \n",
    "    print(f'Scrapping page: {page}')\n",
    "\n",
    "    scrapping_site_url = f'https://www.daraz.pk/catalog/?q=laptop&price=2000-200000&page={page}'\n",
    "\n",
    "    driver.get(scrapping_site_url)\n",
    "    driver.maximize_window()\n",
    "    \n",
    "    try:\n",
    "        total_pages = driver.find_element_by_xpath('//ul[@class=\"ant-pagination \"]/li[position() = (last() - 1)]').text\n",
    "    except:\n",
    "        continue\n",
    "    \n",
    "    daraz_mall = driver.find_elements_by_xpath('//div[@data-qa-locator=\"product-item\"]/div/div/div[2]/div[1]')\n",
    "    for item in daraz_mall:\n",
    "        is_daraz_mall = None\n",
    "        try:\n",
    "            is_daraz_mall = bool(item.find_element_by_tag_name('i'))\n",
    "        except:\n",
    "            is_daraz_mall = False\n",
    "        data_dict['Daraz_Mall'].append(str(is_daraz_mall))\n",
    "\n",
    "    titles = driver.find_elements_by_xpath('//div[@data-qa-locator=\"product-item\"]/div/div/div[2]/div[2]/a')\n",
    "    for title in titles:\n",
    "      data_dict['Title'].append(title.text)\n",
    "\n",
    "    prices = driver.find_elements_by_xpath('//div[@data-qa-locator=\"product-item\"]/div/div/div[2]/div[3]/span')\n",
    "    for price in prices:\n",
    "        data_dict['Price'].append(price.text)\n",
    "\n",
    "    total_ratings = driver.find_elements_by_xpath('//div[@data-qa-locator=\"product-item\"]/div/div/div[2]/div[5]')\n",
    "    for rating in total_ratings:\n",
    "        rating_count = None\n",
    "        try:\n",
    "            rating_container = rating.find_element_by_tag_name('div')\n",
    "            rating_span = rating_container.find_element_by_tag_name('span')\n",
    "            rating_count = rating_span.text\n",
    "        except:\n",
    "            rating_count = \"(0)\"\n",
    "\n",
    "        data_dict['Total_Ratings'].append(rating_count)\n",
    "\n",
    "    countries = driver.find_elements_by_xpath('//div[@data-qa-locator=\"product-item\"]/div/div/div[2]/div[5]/span')\n",
    "    for country in countries:\n",
    "         data_dict['Country'].append(country.text)\n",
    "            \n",
    "    page += 1\n",
    "\n",
    "\n",
    "\n",
    "df = pd.DataFrame.from_dict(data_dict, orient=\"columns\")\n",
    "\n",
    "df['Price'] = df['Price'].apply(lambda x: x.replace('Rs.', '').strip())\n",
    "df['Total_Ratings'] = df['Total_Ratings'].apply(lambda x: x.replace('(', ''))\n",
    "df['Total_Ratings'] = df['Total_Ratings'].apply(lambda x: x.replace(')', ''))\n",
    "\n",
    "df.to_excel(\"scrapped_data.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
